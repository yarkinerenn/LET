import re

import numpy as np
from bson import ObjectId
from openai import OpenAI

from extensions import mongo
import shap
from transformers import pipeline,AutoModelForSequenceClassification,AutoTokenizer
from groq import Groq
from .auth import (
    get_user_api_key_openai,
    get_user_api_key_openrouter,
    get_user_api_key_groq,
)
tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased-finetuned-sst-2-english")
model = AutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased-finetuned-sst-2-english")
classifier = pipeline(
    "text-classification",
    model="distilbert-base-uncased-finetuned-sst-2-english"
)

def pretty_pubmed_qa(data):
    # If data is not a dict, convert it from Python repr to dict first (may require ast.literal_eval)
    if isinstance(data, str):
        import ast
        try:
            data = ast.literal_eval(data)
        except Exception:
            return data  # fallback: just return the string

    context = "\n".join(data.get('contexts', []))
    labels = ", ".join(data.get('labels', []))
    meshes = ", ".join(data.get('meshes', []))
    rr_pred = ", ".join(data.get('reasoning_required_pred', []))
    rf_pred = ", ".join(data.get('reasoning_free_pred', []))
    return (
        f"Context:\n{context}\n"
        f"Labels: {labels}\n"
        f"MeSH Terms: {meshes}\n"
        f"Reasoning Required Prediction: {rr_pred}\n"
        f"Reasoning Free Prediction: {rf_pred}"
    )
def save_explanation_to_db(classification_id, user_id, result_id, explanation_type, content,model_id):
    """Save the explanations generated by the user """
    print(content,model_id,'content and model id ')


    if explanation_type == 'llm':

        update_field = f"results.{result_id}.llm_explanations.{model_id}"
        print('llm saved')


    elif explanation_type == 'shap_plot':
        update_field = f"results.{result_id}.shap_plot_explanation"
        print('shapplot saved')

    elif explanation_type == 'shapwithllm':

        update_field = f"results.{result_id}.shapwithllm_explanations.{model_id}"
        print('shapllm saved')
    else:
        return False



    # Update the classification document
    result = mongo.db.classifications.update_one(
        {
            "_id": ObjectId(classification_id),
            "user_id": ObjectId(user_id),
            f"results.{result_id}": {"$exists": True}
        },
        {
            "$set": {update_field: content}
        }
    )
    print('and the results',result)

    return result.modified_count > 0

def extract_context_explanation(context_pretty_str):
    # Use regex to capture everything between "Context:" and "Labels:"
    match = re.search(r'Context:\n(.*?)\nLabels:', context_pretty_str, re.DOTALL)
    if match:
        return match.group(1).strip()
    return ""
def save_ratings_to_db(classification_id, user_id, result_id, ratings, timestamp):
    update_fields = {
        f"results.{result_id}.ratings": ratings,
    }

    result = mongo.db.classifications.update_one(
        {
            "_id": ObjectId(classification_id),
            "user_id": ObjectId(user_id),
            f"results.{result_id}": {"$exists": True}
        },
        {
            "$set": update_fields
        }
    )

    return result.modified_count > 0

def get_top_phrases(shap_values_obj, instance_idx=0, class_idx=1, top_n=5):
    """From the shapley value extract the most affecting word for the classification"""
    # Extract text segments and SHAP values
    text_segments = shap_values_obj[instance_idx].data
    shap_vals = shap_values_obj[instance_idx].values[:, class_idx]

    # Pair and sort by absolute impact
    paired = sorted(zip(text_segments, shap_vals),
                    key=lambda x: -abs(x[1]))

    # Separate positive and negative impacts
    positive = [(text, val) for text, val in paired if val > 0]
    negative = [(text, val) for text, val in paired if val < 0]

    # Build result string
    result = [
        f"Top {top_n} impactful phrases for instance {instance_idx}:",
        "\n=== Positive Contributions ==="
    ]

    for text, val in positive[:top_n]:
        result.append(f"({val:+.2f}) {text.strip()}")

    result.append("\n=== Negative Contributions ===")

    for text, val in negative[:top_n]:
        result.append(f"({val:+.2f}) {text.strip()}")

    # Also return array of words for SHAP enhanced analysis
    all_words = [text.strip() for text, val in paired[:top_n*2]]  # Get top words from both positive and negative
    
    return "\n".join(result), all_words

def generate_shap_explanation(input_text, label):
    """Generate an explanation using SHAP values"""
    try:
        # Map label to class index, but make sure we check the prediction first
        class_index = 1 if label == 'POSITIVE' else 0

        # Generate the explanation
        pmodel = shap.models.TransformersPipeline(classifier, rescale_to_logits=True)
        _ = pmodel([input_text])  # Trigger internal stuff
        explainer2 = shap.Explainer(pmodel)
        shap_values2 = explainer2([input_text])

        # Check prediction: If prediction is POSITIVE, we need class_index = 0
        # because shap is showing the opposing class's influence
        predicted_class = np.argmax(shap_values2.values.sum(axis=1))
        if predicted_class == 1:  # If predicted POSITIVE, swap the class_index
            class_index = 0  # For POSITIVE predictions, we need to use the negative class index

        output_str, top_words = get_top_phrases(shap_values2, top_n=10)
        plot = shap.plots.text(shap_values2[:, :, class_index], display=False)
        print(output_str)

        return plot, output_str, top_words
    except Exception as e:
        print(f"Error in SHAP explanation: {str(e)}")
        return None, f"Could not generate SHAP explanation: {str(e)}", []
def classify_with_chunks(text, classifier, tokenizer, max_length=512, stride=256):
    """use it if the context windows of the BERT is not big enoguh for a dataset entry"""
    inputs = tokenizer(
        text,
        return_overflowing_tokens=True,
        truncation=True,
        max_length=max_length,
        stride=stride,
        padding=True,
        return_tensors="pt"
    )

    scores = []
    labels = []
    for chunk in inputs['input_ids']:
        decoded = tokenizer.decode(chunk, skip_special_tokens=True)
        try:
            result = classifier(decoded)[0]
            scores.append(result['score'])
            labels.append(result['label'].upper())
        except:
            continue

    if not scores:
        return "NEGATIVE", 0.0

    # Majority voting or average
    avg_score = sum(scores) / len(scores)
    final_label = max(set(labels), key=labels.count)  # majority vote

    return final_label, avg_score

def generate_llm_explanationofdataset(text, label,truelabel, score,provider,model,datatype):
    """Generete generative AI explanation of singel instances in the dataset"""


    try:
        myprompt=''
        if datatype == 'legal':
            myprompt=f"""
                Explain why this holding is correct for the legal statement :
                
                Statement: {text}
                holding: {label} 
                
                Focus on key words and overall tone.
                Keep explanation under 3 sentences.
            """
        elif datatype == 'sentiment':
             myprompt=f"""
                Explain this sentiment analysis result in simple terms:
                
                Text: {text}
                Sentiment: {label} ({score}% confidence)
                
                Focus on key words and overall tone.
                Keep explanation under 3 sentences.
            """
        elif datatype == 'ecqa':
            myprompt=f"""
                Explain this commonsense question answering result in simple terms:
                
                Question: {text}
                Predicted Answer: {label} ({score}% confidence)
                
                Focus on the reasoning behind the answer choice.
                Keep explanation under 3 sentences.
            """
        elif datatype == 'snarks':
            myprompt=f"""
                Explain this sarcasm detection result in simple terms:
                
                Question: {text}
                Predicted Answer: {label} ({score}% confidence)
                
                Focus on the sarcastic elements and reasoning.
                Keep explanation under 3 sentences.
            """
        elif datatype == 'hotel':
            myprompt=f"""
                Explain this hotel review authenticity detection result in simple terms:
                
                Review: {text}
                Prediction: {label} ({score}% confidence)
                
                Focus on the indicators of authenticity or deception.
                Keep explanation under 3 sentences.
            """
        elif datatype == 'medical':
            myprompt=f"""
                Explain this medical question answering result in simple terms:
                
                Question: {text}
                Predicted Answer: {label} ({score}% confidence)
                
                Focus on the medical reasoning and evidence.
                Keep explanation under 3 sentences.
            """
        else:
            myprompt=f"""
               Given the following biomedical question and its context, explain in simple terms why the answer is {label} from given {score}

                Question:{text}
                
                Context: {score}
                
                Predicted Answer: {label} 
                
            """
        if provider == 'openai':

            openai_api_key = get_user_api_key_openai()

            if not openai_api_key:
                return "Error: No OpenAI API key found for this user."

            client = OpenAI(api_key=openai_api_key)

            prompt = myprompt

            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}]
            )

            explanation = response.choices[0].message.content
            return explanation
        elif provider=='openrouter':
            openai_api_key = get_user_api_key_openrouter()

            if not openai_api_key:
                return "Error: No OpenAI API key found for this user."

            client = OpenAI(  base_url="https://openrouter.ai/api/v1",
                              api_key=openai_api_key)


            response = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": myprompt}]
            )

            explanation = response.choices[0].message.content
            return explanation
        else:
            api= get_user_api_key_groq()

            client = Groq(
                api_key=api,
            )

            chat_completion = client.chat.completions.create(
                messages=[
                    {
                        "role": "user",
                        "content":myprompt,
                    }
                ],
                model=model,
            )
            return chat_completion.choices[0].message.content



    except Exception as e:
        print(f"Error: {e}")
        return f"Error: {str(e)}"


def generate_llm_explanation(text, label, score, provider, model, data_type="sentiment"):
    """Generate explanations with generative AI"""
    try:
        # ---- PROMPT TEMPLATES ----
        if data_type == "legal":
            prompt = f"""
                Explain why this holding is correct for the legal statement:
                
                Statement: {text}
                Holding: {label}
                
                Focus on key words and overall legal reasoning.
                Keep explanation under 3 sentences.
            """
        elif data_type == "medical":
            prompt = f"""
                Given the following biomedical question and its context, explain in simple terms why the answer is {label}.
                
                Question: {text}
                Predicted Answer: {label}
                Confidence: {score}
                
                Keep explanation under 3 sentences.
            """
        else:  # Default to sentiment
            prompt = f"""
                Explain this sentiment analysis result in simple terms:
                
                Text: {text}
                Sentiment: {label} ({score}% confidence)
                
                Focus on key words and overall tone.
                Keep explanation under 3 sentences.
            """

        if provider == 'openai':
            openai_api_key = get_user_api_key_openai()
            if not openai_api_key:
                return "Error: No OpenAI API key found for this user."
            client = OpenAI(api_key=openai_api_key)
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}]
            )
            explanation = response.choices[0].message.content
            return explanation

        elif provider == 'groq':
            api = get_user_api_key_groq()
            client = Groq(api_key=api)
            chat_completion = client.chat.completions.create(
                messages=[{"role": "user", "content": prompt}],
                model=model,
            )
            return chat_completion.choices[0].message.content

        elif provider == 'openrouter':
            openai_api_key = get_user_api_key_openrouter()
            if not openai_api_key:
                return "Error: No OpenAI API key found for this user."
            client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=openai_api_key)
            response = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": prompt}]
            )
            explanation = response.choices[0].message.content
            return explanation

    except Exception as e:
        print(f"Error: {e}")
        return f"Error: {str(e)}"
