# routes/explanations.py
from flask import Blueprint, jsonify, request, current_app
from flask_login import login_required, current_user
from bson import ObjectId
from datetime import datetime
import traceback
import requests  # you call back to /api/save-explanation in one branch

from extensions  import mongo

# external clients you already use
from openai import OpenAI
from groq import Groq

# pull key getters exactly as you’ve been using them
from .auth import (
    get_user_api_key_openai,
    get_user_api_key_groq,
    get_user_api_key_openrouter,
)

# helper funcs you already have elsewhere
from .helpers import generate_shap_explanation, generate_llm_explanation, generate_llm_explanationofdataset,save_explanation_to_db
# if you keep extract_context_explanation here too, import it the same way

explanations_bp = Blueprint("explanations", __name__)


@explanations_bp.route('/api/classification/<classification_id>/add_explanation_models', methods=['POST'])
@login_required
def add_explanationmodels_to_classficication(classification_id):
    data = request.get_json()
    explanation_models = data.get('explanation_models', [])
    mongo.db.classifications.update_one(
        {
            "_id": ObjectId(classification_id),
            "user_id": ObjectId(current_user.id)  # Ensure user owns this classification
        },
        {
            "$set": {
                "explanation_models": explanation_models,
                "updated_at": datetime.now()
            }
        }
    )

    return jsonify({
        "message": "Explanation models added successfully",
        "classification_id": classification_id
    }), 200


@explanations_bp.route('/api/save-explanation', methods=['POST'])
@login_required
def save_explanation():
    """Save the explanations generated by the user"""
    try:
        data = request.get_json()
        current_app.logger.debug({"save_explanation_payload": data})

        classification_id = data['classification_id']
        result_id = int(data['result_id'])
        explanation_type = data['explanation_type']
        content = data['content']

        # Map explanation types to database fields
        if explanation_type == 'llm':
            field_map = {'llm': f'results.{result_id}.llm_explanation'}
        elif explanation_type == 'shap_plot':
            field_map = {'shap_plot': f'results.{result_id}.shap_plot_explanation'}
        else:
            field_map = {'shapwithllm': f'results.{result_id}.shapwithllm_explanation'}

        update_field = field_map[explanation_type]

        result = mongo.db.classifications.update_one(
            {
                "_id": ObjectId(classification_id),
                "user_id": ObjectId(current_user.id),
                f"results.{result_id}": {"$exists": True}
            },
            {"$set": {update_field: content}}
        )
        if result.modified_count == 0:
            return jsonify({"error": "Failed to save explanation"}), 400

        return jsonify({"message": "Explanation saved successfully"}), 200

    except Exception as e:
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


@explanations_bp.route('/api/explain', methods=['POST'])
@login_required
def explain_prediction():
    """Generate explanations shap or generative AI explanations for classification"""
    try:
        user_doc = mongo.db.users.find_one({"_id": ObjectId(current_user.id)})
        data = request.json
        current_app.logger.debug({"explain_payload": data})

        prediction_id = data.get('predictionId', 'fromdata')
        classificationId = data.get('classificationId', 'empty')
        datatype = data.get('datatype', 'sentiment')

        if classificationId == 'empty':
            # use user’s preferred explanation provider/model
            provider = user_doc.get('preferred_providerex', 'openai')
            model = user_doc.get('preferred_modelex', 'gpt-3.5-turbo')
        else:
            provider = data.get('provider', 'openai')
            model = data.get('model', 'gpt-3.5-turbo')

        resultId = data.get('resultId')
        predictedlabel = data.get('predictedlabel')
        truelabel = data.get('truelabel')
        confidence = data.get('confidence')
        text = data.get('text')
        explainer_type = data.get('explainer_type', 'llm')

        if prediction_id == 'fromdata':
            # explanation is for a dataset entry
            if not text:
                return jsonify({"error": "Missing text"}), 400

            if explainer_type == 'shap':
                explanation_data, top_words = generate_shap_explanation(text, predictedlabel)
                save_explanation_to_db(classificationId, current_user.id, resultId, 'shap_plot', explanation_data, model)
                return jsonify({'explanation': explanation_data, 'explainer_type': explainer_type, 'top_words': top_words})
            else:
                explanation_text = generate_llm_explanationofdataset(
                    text, predictedlabel, truelabel, confidence, provider, model, datatype
                )
                save_explanation_to_db(classificationId, current_user.id, resultId, 'llm', explanation_text, model)
                return jsonify({"explanation": explanation_text, 'explainer_type': explainer_type})

        else:
            # explanation is requested via dashboard for an existing prediction
            if not prediction_id or not text:
                return jsonify({"error": "Missing prediction_id or text"}), 400

            prediction = mongo.db.predictions.find_one({"_id": ObjectId(prediction_id)})
            if not prediction:
                return jsonify({"error": "Prediction not found"}), 404

            if explainer_type == 'shap':
                explanation_data, top_words = generate_shap_explanation(text, prediction['label'])
                return jsonify({'explanation': explanation_data, 'explainer_type': explainer_type, 'top_words': top_words})
            else:
                explanation_text = generate_llm_explanation(text, prediction['label'], prediction['score'], provider, model)
                return jsonify({"explanation": explanation_text, 'explainer_type': explainer_type})

    except Exception as e:
        current_app.logger.exception(f"Error generating explanation: {str(e)}")
        return jsonify({"error": str(e)}), 500


@explanations_bp.route('/api/explain_withshap', methods=['POST'])
@login_required
def generate_llm_explanation_of_shap():
    """Generate generative AI explanation with prompting SHAP values"""
    try:
        data = request.json
        shapwords = data.get('shapwords')
        classificationId = data.get('classificationId', 'empty')
        resultId = data.get('resultId')
        text = data.get('text')
        prediction_id = data.get('predictionId')

        user_doc = mongo.db.users.find_one({"_id": ObjectId(current_user.id)})
        if classificationId == 'empty':
            provider = user_doc.get('preferred_providerex', 'openai')
            model = user_doc.get('preferred_modelex', 'gpt-3.5-turbo')
        else:
            provider = data.get('provider', 'openai')
            model = data.get('model', 'gpt-3.5-turbo')

        if prediction_id:
            if not prediction_id or not text:
                return jsonify({"error": "Missing prediction_id or text"}), 400

            prediction = mongo.db.predictions.find_one({"_id": ObjectId(prediction_id)})
            if not prediction:
                return jsonify({"error": "Prediction not found"}), 404

            label = prediction['label']
            score = prediction['score']

            if provider == 'openai':
                openai_api_key = get_user_api_key_openai()
                if not openai_api_key:
                    return "Error: No OpenAI API key found for this user."
                client = OpenAI(api_key=openai_api_key)

                prompt = f"""
Explain this sentiment analysis result in simple terms with most affecting words provided by SHAP:

Text: {text}
Sentiment: {label} ({score}% confidence)

shap:
{shapwords}

Focus on key words and overall tone.
Keep explanation under 3 sentences.
"""
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "user", "content": prompt}]
                )
                explanation = response.choices[0].message.content
                save_explanation_to_db(classificationId, current_user.id, resultId, 'shapwithllm', explanation, model)
                return explanation

            elif provider == 'grok':
                api = get_user_api_key_groq()
                client = Groq(api_key=api)
                chat_completion = client.chat.completions.create(
                    messages=[{"role": "user", "content": f"""
Explain this sentiment analysis result in simple terms with most affecting words provided by SHAP:

Text: {text}
Sentiment: {label} ({score}% confidence)

shap:
{shapwords}

Focus on key words and overall tone.
Keep explanation under 3 sentences.
"""}],
                    model=model,
                )
                content = chat_completion.choices[0].message.content
                save_explanation_to_db(classificationId, current_user.id, resultId, 'shapwithllm', content, model)
                return content

            elif provider == 'openrouter':
                openai_api_key = get_user_api_key_openrouter()
                if not openai_api_key:
                    return "Error: No OpenAI API key found for this user."
                client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=openai_api_key)

                prompt = f"""
Explain this sentiment analysis result in simple terms with most affecting words provided by SHAP:

Text: {text}
Sentiment: {label} ({score}% confidence)

shap:
{shapwords}

Focus on key words and overall tone.
Keep explanation under 3 sentences.
"""
                response = client.chat.completions.create(
                    model=model,
                    messages=[{"role": "user", "content": prompt}]
                )
                explanation = response.choices[0].message.content
                save_explanation_to_db(classificationId, current_user.id, resultId, 'shapwithllm', explanation, model)
                return explanation

        else:
            # no prediction_id: use provided text/label/score
            if not text:
                return jsonify({"error": "Missing prediction_id or text"}), 400

            label = data.get('label')
            score = data.get('confidence')

            if provider == 'openai':
                openai_api_key = get_user_api_key_openai()
                if not openai_api_key:
                    return "Error: No OpenAI API key found for this user."
                client = OpenAI(api_key=openai_api_key)

                prompt = f"""
Explain this sentiment analysis result in simple terms with most affecting words provided by SHAP:

Text: {text}
Sentiment: {label} ({score}% confidence)

shap:
{shapwords}

Focus on key words and overall tone.
Keep explanation under 3 sentences.
"""
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "user", "content": prompt}]
                )
                explanation = response.choices[0].message.content

                # You also call your internal endpoint here in original code
                requests.post('http://localhost:5000/api/save-explanation', json={
                    'classification_id': classificationId,
                    'result_id': int(resultId),
                    'explanation_type': 'shapwithllm',
                    'content': explanation
                })
                save_explanation_to_db(classificationId, current_user.id, resultId, 'shapwithllm', explanation, model)
                return explanation

            elif provider == 'grok':
                api = get_user_api_key_groq()
                client = Groq(api_key=api)
                chat_completion = client.chat.completions.create(
                    messages=[{"role": "user", "content": f"""
Explain this sentiment analysis result in simple terms with most affecting words provided by SHAP:

Text: {text}
Sentiment: {label} ({score}% confidence)

shap:
{shapwords}

Focus on key words and overall tone.
Keep explanation under 3 sentences.
"""}],
                    model=model,
                )
                content = chat_completion.choices[0].message.content
                save_explanation_to_db(classificationId, current_user.id, resultId, 'shapwithllm', content, model)
                return content

            elif provider == 'openrouter':
                openai_api_key = get_user_api_key_openrouter()
                if not openai_api_key:
                    return "Error: No OpenAI API key found for this user."
                client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=openai_api_key)

                prompt = f"""
Explain this sentiment analysis result in simple terms with most affecting words provided by SHAP:

Text: {text}
Sentiment: {label} ({score}% confidence)

shap:
{shapwords}

Focus on key words and overall tone.
Keep explanation under 3 sentences.
"""
                response = client.chat.completions.create(
                    model=model,
                    messages=[{"role": "user", "content": prompt}]
                )
                explanation = response.choices[0].message.content
                save_explanation_to_db(classificationId, current_user.id, resultId, 'shapwithllm', explanation, model)
                return explanation

        return jsonify({"error": "Invalid provider or missing return path"}), 400

    except Exception as e:
        current_app.logger.exception(f"Error in /api/explain_withshap: {e}")
        return jsonify({"error": str(e)}), 500